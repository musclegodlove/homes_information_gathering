import requests
from bs4 import BeautifulSoup
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build

# Google Sheets APIの認証情報
SCOPES = ['https://www.googleapis.com/auth/spreadsheets']
SERVICE_ACCOUNT_FILE = 'credentials.json'

credentials = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)
service = build('sheets', 'v4', credentials=credentials)

# 取得したいGoogleスプレッドシートIDとシート名
SPREADSHEET_ID = '1jMkc3ZGFZKgulzoN8VuFLk2wK3r-UA3RWYJvyM_d0Fs'  # ここにスプレッドシートIDを入力
SHEET_NAME = 'test sheet'

def fetch_house_info(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')




    # ここでは例として、築年数、住所、家賃を取得する
    # 実際のセレクタは対象のWebページによって異なります
    built_year = soup.select_one('.built-year').text.strip()
    address = soup.select_one('.address').text.strip()
    rent = soup.select_one('.rent').text.strip()

    return [built_year, address, rent]

def write_to_sheets(data):
    sheet = service.spreadsheets()
    range_ = f'{SHEET_NAME}!A1:C1'
    value_input_option = 'RAW'
    value_range_body = {'values': [data]}
    request = sheet.values().update(spreadsheetId=SPREADSHEET_ID, range=range_,
                                    valueInputOption=value_input_option, body=value_range_body)
    response = request.execute()
    print(f'Data written to {SHEET_NAME}!A1:C1')

if __name__ == '__main__':
    url = 'https://www.homes.co.jp/chintai/room/bae68845fb1590cae63dc06724091baf1a36a626/?bid=1392040048605'  # ここに情報を取得したいWebページのURLを入力
    house_info = fetch_house_info(url)
    write_to_sheets(house_info)
